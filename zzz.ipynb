{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(timestamp=6):\n",
    "        \n",
    "        csv_files = pickle.load(open('Tech_data_path.pkl', 'rb'))\n",
    "        \n",
    "        \n",
    "        def X_Y(df, timestamp):\n",
    "            X, Y = [], []\n",
    "            for i in range(0, len(df) - timestamp - 1):\n",
    "                X.append(df[i:(i + timestamp), :])\n",
    "                Y.append(df[i + timestamp, :])\n",
    "\n",
    "            if len(df) >= timestamp:\n",
    "                X.append(df[-timestamp:, :])\n",
    "                Y.append(df[-1, :])\n",
    "\n",
    "            return np.array(X), np.array(Y)\n",
    "        \n",
    "        def get_confidence_interval(errors, confidence=0.95):\n",
    "            mean_error = np.mean(errors)\n",
    "            standard_error = np.std(errors, ddof=1) / np.sqrt(len(errors))\n",
    "\n",
    "            t_score = np.abs(stats.t.ppf((1 + confidence) / 2, len(errors) - 1))\n",
    "\n",
    "            lower_bound = mean_error - t_score * standard_error\n",
    "            upper_bound = mean_error + t_score * standard_error\n",
    "            \n",
    "             # Inverse transform to get prices in the original scale\n",
    "            lower_bound = scaler.inverse_transform([[0, 0, 0, lower_bound]])[0, -1]\n",
    "            upper_bound = scaler.inverse_transform([[0, 0, 0, upper_bound]])[0, -1]\n",
    "\n",
    "            return round(lower_bound), round(upper_bound)\n",
    "\n",
    "        def get_recommendation(model, xtest, ytest, scaler, last_day_price):\n",
    "            pred = model.predict(xtest)\n",
    "\n",
    "            last_sequence = xtest[-1]\n",
    "            last_sequence = last_sequence.reshape(1, last_sequence.shape[0], last_sequence.shape[1])\n",
    "\n",
    "            next_day_pred = model.predict(last_sequence)\n",
    "            next_day_pred_original_scale = scaler.inverse_transform(next_day_pred)\n",
    "            next_day_closing_price = next_day_pred_original_scale[0, -1]\n",
    "\n",
    "            errors = np.abs(ytest - pred)\n",
    "            confidence_interval = get_confidence_interval(errors)\n",
    "\n",
    "            accuracy = r2_score(ytest, pred)\n",
    "            current_price = last_day_price[-1]\n",
    "\n",
    "            recommendation = ((next_day_closing_price - current_price) / current_price) * 100\n",
    "\n",
    "            return current_price, recommendation, accuracy, confidence_interval\n",
    "\n",
    "        result_data = []\n",
    "        for file_path in csv_files:\n",
    "            \n",
    "            input_filename = os.path.basename(file_path).split(\".\")[0]\n",
    "            \n",
    "            df = pd.read_csv(file_path)\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime']).dt.date\n",
    "\n",
    "            original_data = df[['Open', 'High', 'Low',\"Close\"]].values\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_data = scaler.fit_transform(original_data)\n",
    "\n",
    "            train_size = int(len(scaled_data) * 0.70)\n",
    "            xtrain, ytrain = X_Y(scaled_data[0:train_size], timestamp)\n",
    "            xtest, ytest = X_Y(scaled_data[train_size:], timestamp)\n",
    "\n",
    "            xtrain = xtrain.reshape(xtrain.shape[0], xtrain.shape[1], 4)\n",
    "            xtest = xtest.reshape(xtest.shape[0], xtest.shape[1], 4)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(50, return_sequences=True, input_shape=(xtrain.shape[1], 4)))\n",
    "            model.add(LSTM(50, return_sequences=True))\n",
    "            model.add(LSTM(50))\n",
    "            model.add(Dense(4))\n",
    "            model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "            history = model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=1, batch_size=64, verbose=1)\n",
    "\n",
    "            current_price, recommendation, accuracy, confidence_interval  = get_recommendation(model, xtest, ytest, scaler, df['Close'].values)\n",
    "            result_data.append({\n",
    "                \"stock_ticker\": input_filename,\n",
    "                \"current_price\": round(current_price,2),\n",
    "                \"recommendation\":  f\"{round(recommendation,2)}%\",\n",
    "                \"accuracy\": f\"{round(accuracy,2)*100}%\",\n",
    "                \"confidence_interval\": confidence_interval\n",
    "            })\n",
    "        # json.dump(result_data, open('Output/result_data.json', 'w'))\n",
    "        print(result_data)\n",
    "        return result_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 6s 69ms/step - loss: 0.1133 - val_loss: 0.0218\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 7s 92ms/step - loss: 0.0584 - val_loss: 0.0033\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 7s 66ms/step - loss: 0.1504 - val_loss: 0.0395\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "19/19 [==============================] - 8s 83ms/step - loss: 0.0337 - val_loss: 0.0073\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "[{'stock_ticker': 'HDFC_data', 'current_price': 2733.0, 'recommendation': '5.31%', 'accuracy': '-147.0%', 'confidence_interval': (2331, 2336)}, {'stock_ticker': 'LNT_data', 'current_price': 2565.0, 'recommendation': '-0.11%', 'accuracy': '79.0%', 'confidence_interval': (1785, 1790)}, {'stock_ticker': 'TCS_data', 'current_price': 3397.5, 'recommendation': '4.33%', 'accuracy': '-108.0%', 'confidence_interval': (3063, 3070)}, {'stock_ticker': 'TITAN_data', 'current_price': 3029.95, 'recommendation': '-5.63%', 'accuracy': '78.0%', 'confidence_interval': (2344, 2352)}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'stock_ticker': 'HDFC_data',\n",
       "  'current_price': 2733.0,\n",
       "  'recommendation': '5.31%',\n",
       "  'accuracy': '-147.0%',\n",
       "  'confidence_interval': (2331, 2336)},\n",
       " {'stock_ticker': 'LNT_data',\n",
       "  'current_price': 2565.0,\n",
       "  'recommendation': '-0.11%',\n",
       "  'accuracy': '79.0%',\n",
       "  'confidence_interval': (1785, 1790)},\n",
       " {'stock_ticker': 'TCS_data',\n",
       "  'current_price': 3397.5,\n",
       "  'recommendation': '4.33%',\n",
       "  'accuracy': '-108.0%',\n",
       "  'confidence_interval': (3063, 3070)},\n",
       " {'stock_ticker': 'TITAN_data',\n",
       "  'current_price': 3029.95,\n",
       "  'recommendation': '-5.63%',\n",
       "  'accuracy': '78.0%',\n",
       "  'confidence_interval': (2344, 2352)}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = json.load(open('Output/result_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stock_ticker': 'HDFC_data',\n",
       " 'current_price': 2733.0,\n",
       " 'recommendation': '0.72%',\n",
       " 'accuracy': '84.0%',\n",
       " 'confidence_interval': [2254, 2258]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
